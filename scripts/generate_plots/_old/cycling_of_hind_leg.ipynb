{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "With the components on the backwards stepping identified, we now want to undertsand how the sequential unfolding emerges.\n",
    "\n",
    "## Part 3A\n",
    "The first answer can be obtained by looking at information flow or graph cycling at the control level, which we illustrate here.\n",
    "\n",
    "## Part 3B\n",
    "We can complement this information using simulations of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vnc_networks import MANC, params\n",
    "from vnc_networks.specific_neurons import (\n",
    "    mdn_helper,\n",
    "    motor_neurons_helper,\n",
    "    sensory_neurons_helper,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Directories\n",
    "manc_version = \"v1.2\"\n",
    "MDN_DIR = \"MDN_project\"\n",
    "FIG_DIR = MANC(manc_version).get_fig_dir()\n",
    "MDN_FIGS = os.path.join(FIG_DIR, MDN_DIR)\n",
    "os.makedirs(MDN_FIGS, exist_ok=True)\n",
    "\n",
    "# Analysis choices\n",
    "side = \"RHS\"\n",
    "leg = \"h\"\n",
    "\n",
    "# Save?\n",
    "savefigs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3A: Graph at the premotor level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3Aa: Visualisation of the graph\n",
    "\n",
    "We want to draw the graph including MDNs, important premotor neurons, motor neurons and sensory neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR = MANC(manc_version)\n",
    "split_mdn_vnc = mdn_helper.get_vnc_split_MDNs_by_neuropil(\n",
    "    not_connected=mdn_helper.get_mdn_bodyids()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mdns\n",
    "mdn_uids = mdn_helper.get_subdivided_mdns(\n",
    "    split_mdn_vnc,\n",
    "    neuropil=leg,\n",
    "    # side=side,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the key premotor neurons\n",
    "premotor_df = pd.read_csv(\n",
    "    os.path.join(MDN_FIGS, \"motor_clusters_right_hind_leg_MDN_premotor_hubs.csv\"),\n",
    ")\n",
    "pmn_bodyids = premotor_df[\"body_id\"].values\n",
    "pmn_uids = split_mdn_vnc.get_uids_from_bodyids(pmn_bodyids) # should match the \"uid\" column, but in case we change the connection loaded this is safer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hind leg, right side leg motor neurons\n",
    "mn_uids = motor_neurons_helper.get_leg_motor_neurons(\n",
    "    data=split_mdn_vnc,\n",
    "    leg=leg,\n",
    "    side=side,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hind leg, right side leg sensory neurons\n",
    "sn_uids = sensory_neurons_helper.get_leg_sensory_neurons(\n",
    "    data=split_mdn_vnc,\n",
    "    leg=leg,\n",
    "    side=side,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subgraph\n",
    "all_nodes = set(pmn_uids)  #| set(mdn_uids)  #  | set(mn_uids)| set(sn_uids)\n",
    "subgraph = split_mdn_vnc.subgraph(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "ax = subgraph.display_graph(ax=ax, save=False, label_nodes=True, method=\"circular\")\n",
    "\n",
    "if savefigs:\n",
    "    os.makedirs(os.path.join(MDN_FIGS, \"tmp\"), exist_ok=True)\n",
    "    fig.savefig(\n",
    "        os.path.join(MDN_FIGS, \"tmp\", f\"MDN_premotor_{leg}_leg_{side}_subgraph.png\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The direct connections between the premotor neurons is coherent with the putative motor primitives that are controlled. Many of the connections are missing when looking only at direct paths, but the ones that exist either inhibit movements that are directly in opposition, or favour a transition from stance to swing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3Ab: Graph random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using update rules that are based on the graph, we can simulate the random walk of the graph. This will give us an idea of the information flow of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_weights(graph, scale_factor):\n",
    "    \"\"\"\n",
    "    Scale the weights of edges in the graph by a given factor.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: NetworkX DiGraph, the input graph.\n",
    "    - scale_factor: Factor to scale edge weights by.\n",
    "\n",
    "    Returns:\n",
    "    - A new graph with scaled edge weights.\n",
    "    \"\"\"\n",
    "    new_graph = graph.copy()\n",
    "    for u, v, data in new_graph.edges(data=True):\n",
    "        data[\"weight\"] *= scale_factor\n",
    "    return new_graph\n",
    "\n",
    "\n",
    "def initialize_activation_levels(graph):\n",
    "    \"\"\"\n",
    "    Initialize activation levels for each node in the graph.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: NetworkX DiGraph, the input graph.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with nodes as keys and initial activation levels as values.\n",
    "    \"\"\"\n",
    "    nb_nodes = len(graph.nodes())\n",
    "    # generate a random number on a gaussian distribution centered around 1\n",
    "    rnd = np.random.normal(1, 0.3, nb_nodes)\n",
    "    return {node: rnd[i] / nb_nodes for i, node in enumerate(graph.nodes())}\n",
    "\n",
    "\n",
    "def update_activation_levels(\n",
    "    graph, activation_levels, decay_factor=0.9,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stochastically update activation levels based on excitatory and inhibitory influences.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: NetworkX DiGraph, the input graph.\n",
    "    - activation_levels: Dictionary with current activation levels.\n",
    "    - decay_factor: Factor to decay activation levels.\n",
    "    - update_prob: Probability of updating each node.\n",
    "\n",
    "    Returns:\n",
    "    - Updated activation levels.\n",
    "    \"\"\"\n",
    "    new_activation_levels = activation_levels.copy()\n",
    "\n",
    "    for node in graph.nodes():\n",
    "        total_influence = 0\n",
    "        for neighbor in graph.predecessors(node):\n",
    "            weight = graph[neighbor][node].get(\"weight\", 1)\n",
    "            total_influence += weight * activation_levels[neighbor]\n",
    "\n",
    "        # Update activation level based on total influence and decay factor\n",
    "        new_activation_levels[node] = max(\n",
    "            0, (activation_levels[node] + total_influence )* decay_factor  \n",
    "        )\n",
    "\n",
    "    # Normalize activation levels\n",
    "    total_activation = np.sum(list(new_activation_levels.values()))\n",
    "    if total_activation > 0:\n",
    "        new_activation_levels = {\n",
    "            node: level / total_activation\n",
    "            for node, level in new_activation_levels.items()\n",
    "        }\n",
    "\n",
    "    return new_activation_levels\n",
    "\n",
    "\n",
    "def simulate_activation_spread(\n",
    "    graph, steps, decay_factor=0.9, graph_scale_factor=1.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate the stochastic spread of activation levels over time.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: NetworkX DiGraph, the input graph.\n",
    "    - steps: Number of simulation steps.\n",
    "    - decay_factor: Factor to decay activation levels.\n",
    "    - update_prob: Probability of updating each node.\n",
    "\n",
    "    Returns:\n",
    "    - Final activation levels after simulation.\n",
    "    \"\"\"\n",
    "    scaled_graph = scale_weights(graph, graph_scale_factor)\n",
    "    activation_levels = initialize_activation_levels(scaled_graph)\n",
    "    activities = {node: [activation_levels[node]] for node in scaled_graph.nodes()}\n",
    "\n",
    "    for _ in range(steps):\n",
    "        activation_levels = update_activation_levels(\n",
    "            scaled_graph, activation_levels, decay_factor\n",
    "        )\n",
    "        activities = {node: activities[node] + [activation_levels[node]] for node in graph.nodes()}\n",
    "\n",
    "    return activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant nodes for information flow\n",
    "# hind leg motor neurons\n",
    "mns = motor_neurons_helper.get_leg_motor_neurons(\n",
    "    data=split_mdn_vnc,\n",
    "    leg=leg,\n",
    ")\n",
    "# hind leg sensory neurons\n",
    "sns = sensory_neurons_helper.get_leg_sensory_neurons(\n",
    "    data=split_mdn_vnc,\n",
    "    leg=leg,\n",
    ")\n",
    "# interneurons in the T3 neuropils\n",
    "t3s = split_mdn_vnc.get_neuron_ids(\n",
    "    {\"neuropil\":\"T3\"},\n",
    ")\n",
    "\n",
    "all_nodes = list(set(mdn_uids) | set(mns) | set(sns) | set(t3s))\n",
    "graph = split_mdn_vnc.get_nx_graph(nodes=all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the avergae sum of weights coming into a node of the network\n",
    "# We use that value to scale the weights of the edges\n",
    "\n",
    "displayed_nodes = pmn_uids\n",
    "incoming_weights = []\n",
    "for node in pmn_uids:\n",
    "    predecessors = graph.predecessors(node)\n",
    "    # get all the weights of the edges from predecessors to node\n",
    "    edges = [graph[pre][node].get(\"weight\", 1) for pre in predecessors]\n",
    "    incoming_weights.append(np.abs(np.sum(edges)))\n",
    "print(f\"Median incoming weight: {np.median(incoming_weights)}\")\n",
    "print(f\"Average incoming weight: {np.mean(incoming_weights)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate the stochastic spread of activation levels\n",
    "steps = 150\n",
    "nb_simulations = 10\n",
    "decay_factor = 1\n",
    "weight_scaling = 1 / np.mean(\n",
    "    incoming_weights\n",
    ") # 0.2 # translate the unknown scaling between weights and synapse count\n",
    "\n",
    "multi_seed_final_activation_levels = {node: [] for node in graph.nodes()}\n",
    "\n",
    "for i in range(nb_simulations):\n",
    "    print(f\"Simulation {i+1}/{nb_simulations}\")\n",
    "    final_activation_levels = simulate_activation_spread(\n",
    "        graph, steps, decay_factor, weight_scaling\n",
    "    )\n",
    "    for node, levels in final_activation_levels.items():\n",
    "        multi_seed_final_activation_levels[node].extend(levels)\n",
    "\n",
    "displayed_nodes = pmn_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show time series for displayed nodes\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for node in displayed_nodes:\n",
    "    ax.plot(multi_seed_final_activation_levels[node], label=node)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Activation level\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "if savefigs:\n",
    "    fig.savefig(\n",
    "        os.path.join(MDN_FIGS, \"tmp\", f\"MDN_premotor_{leg}_leg_{side}_activation_time_series.png\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find maximum time window to distinguish cross-correlation from auto-correlation\n",
    "from scipy.signal import correlate\n",
    "\n",
    "for node in displayed_nodes:\n",
    "    corr = correlate(\n",
    "        multi_seed_final_activation_levels[node],\n",
    "        multi_seed_final_activation_levels[node],\n",
    "    )\n",
    "    corr = corr[len(corr) // 2 - steps // 2 : len(corr) // 2 + steps // 2]\n",
    "    corr /= np.max(corr)\n",
    "    lags = np.arange(-len(corr) // 2, len(corr) // 2)\n",
    "    plt.plot(\n",
    "        lags,\n",
    "        corr,\n",
    "        label=f\"{node}\",\n",
    "    )\n",
    "plt.legend()\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Cross-correlation\")\n",
    "\n",
    "if savefigs:\n",
    "    plt.savefig(\n",
    "        os.path.join(MDN_FIGS, \"tmp\", f\"MDN_premotor_{leg}_leg_{side}_cross_correlation.png\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relative cross-correlation between the nodes for one specific input\n",
    "from scipy.signal import correlate\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "node_a = pmn_uids[0]\n",
    "for j, node_b in enumerate(pmn_uids):\n",
    "    corr = correlate(\n",
    "        multi_seed_final_activation_levels[node_a],\n",
    "        multi_seed_final_activation_levels[node_b],\n",
    "    )\n",
    "    corr = corr[len(corr) // 2 - steps // 2 : len(corr) // 2 + steps // 2]\n",
    "    corr /= np.max(corr)\n",
    "    lags = np.arange(-len(corr) // 2, len(corr) // 2)\n",
    "    ax.plot(\n",
    "        lags,\n",
    "        corr,\n",
    "        label=f\"{node_b}\",\n",
    "    )\n",
    "    # Detect the max and show it as a dot\n",
    "    max_idx = np.argmax(corr)\n",
    "    ax.plot(lags[max_idx], corr[max_idx], \"ro\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Lag\")\n",
    "ax.set_ylabel(\"Cross-correlation\")\n",
    "\n",
    "if savefigs:\n",
    "    fig.savefig(\n",
    "        os.path.join(MDN_FIGS, \"tmp\", f\"MDN_premotor_{leg}_leg_{side}_cross_correlation_relative.png\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second peak in neuron self-cross-correlation at 25 steps. This means that all relevant mutual shifts should be analysed within that window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "\n",
    "# Define the colormap for negative values (blue to white)\n",
    "colors_negative = [\n",
    "    (1, 1, 1),  # White for large negative values\n",
    "    (0, 0.4, 0.7),  # Bright blue for negative values close to 0\n",
    "]\n",
    "\n",
    "# Define the colormap for positive values (red to white)\n",
    "colors_positive = [\n",
    "    (0.6, 0.05, 0.04),  # Bright red for positive values close to 0\n",
    "    (1, 1, 1),  # White for large positive values\n",
    "]\n",
    "\n",
    "# Create the colormaps\n",
    "cmap_negative = LinearSegmentedColormap.from_list(\"cmap_negative\", colors_negative)\n",
    "cmap_positive = LinearSegmentedColormap.from_list(\"cmap_positive\", colors_positive)\n",
    "\n",
    "neg_entries = cmap_negative(np.linspace(0, 1, 128))[:-1]\n",
    "black_entry = np.array([(0, 0, 0, 1), (0, 0, 0, 1)])\n",
    "pos_entries = cmap_positive(np.linspace(0, 1, 128))[1:]\n",
    "# Concatenate the colormaps in one colormap, not stacking but flattening\n",
    "colors_combined = np.concatenate([neg_entries, black_entry, pos_entries], axis=0)\n",
    "\n",
    "# Create the combined colormap\n",
    "custom_cmap = ListedColormap(colors_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the phase lag between the displayed neurons\n",
    "from scipy.signal import correlate\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "visualised_nodes = [7024,11907, 21924,9595,19455,15581,9431]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Identify the lags\n",
    "lag_matrix = np.zeros((len(visualised_nodes), len(visualised_nodes)))\n",
    "for i, nodeA in enumerate(visualised_nodes):\n",
    "    for j, nodeB in enumerate(visualised_nodes):\n",
    "        corr = correlate(\n",
    "            multi_seed_final_activation_levels[nodeA],\n",
    "            multi_seed_final_activation_levels[nodeB],\n",
    "        )\n",
    "        corr = corr[len(corr) // 2 - steps // 2 : len(corr) // 2 + steps // 2]\n",
    "        corr /= np.max(corr)\n",
    "        lags = np.arange(-len(corr) // 2, len(corr) // 2)\n",
    "        # detect where the max occurs\n",
    "        max_idx = np.argmax(corr)\n",
    "        max_lag = lags[max_idx]\n",
    "        lag_matrix[i, j] = max_lag\n",
    "\n",
    "maximum_lag = np.max(np.abs(lag_matrix))\n",
    "im0 = axs[0].matshow(\n",
    "    lag_matrix, cmap=custom_cmap, vmin=-1 * maximum_lag, vmax=maximum_lag\n",
    ")\n",
    "# label the axes with the neuron names\n",
    "axs[0].set_xticks(\n",
    "    range(len(visualised_nodes)), [str(n) for n in visualised_nodes], rotation=90\n",
    ")\n",
    "axs[0].set_yticks(range(len(visualised_nodes)), [str(n) for n in visualised_nodes])\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(im0)\n",
    "cbar.set_label(\"Lag (time steps)\")\n",
    "\n",
    "# Shift the activation levels to account for the phase lag\n",
    "corr = np.zeros((len(visualised_nodes), len(visualised_nodes)))\n",
    "for i, nodeA in enumerate(visualised_nodes):\n",
    "    shifted_activation_levels = multi_seed_final_activation_levels.copy()\n",
    "    for j, nodeB in enumerate(visualised_nodes):\n",
    "        if i != j:\n",
    "            shift = int(lag_matrix[i, j])\n",
    "            shifted_activation_levels[nodeB] = np.roll(\n",
    "                multi_seed_final_activation_levels[nodeB], shift\n",
    "            )\n",
    "        # compute the cross-correlation\n",
    "        corr[i, j], _ = pearsonr(\n",
    "            multi_seed_final_activation_levels[nodeA], shifted_activation_levels[nodeB]\n",
    "        )\n",
    "im2 = axs[1].matshow(corr, cmap=params.grey_heatmap, vmin=-1, vmax=1)\n",
    "# label the axes with the neuron names\n",
    "axs[1].set_xticks(\n",
    "    range(len(visualised_nodes)), [str(n) for n in visualised_nodes], rotation=90\n",
    ")\n",
    "axs[1].set_yticks(range(len(visualised_nodes)), [str(n) for n in visualised_nodes])\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(im2)\n",
    "cbar.set_label(\"Correlation coefficient lag corrected\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if savefigs:\n",
    "    fig.savefig(\n",
    "        os.path.join(MDN_FIGS, \"tmp\", f\"MDN_premotor_{leg}_leg_{side}_lag_matrix.png\"),\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmn_sorted = split_mdn_vnc.list_neuron_properties(visualised_nodes)\n",
    "pmn_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video_of_activation_specific_nodes(\n",
    "        graph: nx.DiGraph, # the graph\n",
    "        pos: dict, # positions of the nodes of interest\n",
    "        activation_levels: dict[int: list[float]], # activation levels of the nodes of interest\n",
    "):\n",
    "        \"\"\" \n",
    "        Create an image for each of the time steps (number of steps in activation_levels).\n",
    "        The image shows the activation levels of the nodes of interest as colours on the\n",
    "        nodes of the graph, visualised as circles.\n",
    "        A colour bar shows the mapping between activation level and colour.\n",
    "        \"\"\"\n",
    "        # Create a colour map where the max value corresponds to the top colour\n",
    "        cmap = plt.cm.get_cmap(params.red_heatmap)\n",
    "        max_value = max([max(activation_levels[node][1:]) for node in pos.keys()])\n",
    "        norm = plt.Normalize(vmin=0, vmax=max_value)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "        # Create subgraph with only the nodes of interest\n",
    "        subgraph = graph.subgraph(pos.keys())\n",
    "\n",
    "        # Identify the number of time steps\n",
    "        num_steps = len(activation_levels[list(activation_levels.keys())[0]])\n",
    "\n",
    "        # create a directory to save the images\n",
    "        os.makedirs(os.path.join(MDN_FIGS,\"tmp\",\"frames\"), exist_ok=True)\n",
    "\n",
    "        # Draw the nodes\n",
    "        for step in range(1, num_steps):\n",
    "            # Create a dictionary of node colours according to the map defined above\n",
    "            node_colors = {\n",
    "                node: cmap(norm(activation_levels[node][step])) for node in activation_levels.keys()\n",
    "            }\n",
    "\n",
    "            # Create a figure and axis\n",
    "            fig, ax = plt.subplots(figsize=(4,4))\n",
    "            ax.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "\n",
    "            # Draw the nodes\n",
    "            nx.draw_networkx_nodes(\n",
    "                subgraph,\n",
    "                pos=pos,\n",
    "                node_color=[node_colors[node] for node in subgraph.nodes()],\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "            # Add a color bar\n",
    "            cbar = plt.colorbar(sm, ax=ax)\n",
    "            cbar.set_label(\"Activation level\")\n",
    "\n",
    "            # Save the image\n",
    "            fig.savefig(\n",
    "                os.path.join(MDN_FIGS, \"tmp\", \"frames\", f\"frame_{step:03d}.png\"),\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=300,\n",
    "            )\n",
    "\n",
    "            # Close the figure\n",
    "            plt.close(fig)\n",
    "            del fig, ax\n",
    "\n",
    "\n",
    "        # Create a video from the saved frames\n",
    "        video_path = os.path.join(MDN_FIGS, \"tmp\", \"videos\")\n",
    "        os.makedirs(video_path, exist_ok=True)\n",
    "        path = os.path.join(video_path, \"activation_spread.mp4\")\n",
    "\n",
    "        with imageio.get_writer(path, fps=15) as writer:\n",
    "            for i in range(1, num_steps):\n",
    "                frame_filename = f'frame_{i:03d}.png'\n",
    "                frame_dir = os.path.join(MDN_FIGS, \"tmp\", \"frames\", frame_filename)\n",
    "                writer.append_data(imageio.imread(frame_dir))\n",
    "                os.remove(\n",
    "                    frame_dir\n",
    "                )  # Optionally remove the frame file after adding it to the video\n",
    "\n",
    "        print(\"Video creation complete.\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "focus_nodes = pmn_uids\n",
    "display_graph = graph.subgraph(focus_nodes)\n",
    "pos = nx.circular_layout(display_graph)\n",
    "\n",
    "make_video_of_activation_specific_nodes(\n",
    "    graph=graph,\n",
    "    pos=pos,\n",
    "    activation_levels=multi_seed_final_activation_levels,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connectomes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
